# Project Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Slack Workspace                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Channels  â”‚  â”‚    DMs     â”‚  â”‚  Slash Commands      â”‚  â”‚
â”‚  â”‚  @BotName  â”‚  â”‚  Messages  â”‚  â”‚  /bot-help, etc.     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚  Socket Mode â”‚
                    â”‚  Connection  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       slack_bot.py (Main App)       â”‚
        â”‚  - Event Listeners                   â”‚
        â”‚  - Command Handlers                  â”‚
        â”‚  - Message Routing                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                   â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  llama_ai.py    â”‚   â”‚ knowledge_base â”‚
      â”‚  - AI Queries   â”‚   â”‚   _manager.py  â”‚
      â”‚  - History      â”‚   â”‚  - Doc Loading â”‚
      â”‚  - Prompts      â”‚   â”‚  - Embedding   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  - Search      â”‚
               â”‚            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Ollama     â”‚   â”‚   ChromaDB    â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚  Vector Store â”‚
        â”‚ â”‚  Llama    â”‚ â”‚   â”‚               â”‚
        â”‚ â”‚  Model    â”‚ â”‚   â”‚  Embeddings   â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

### User Query Processing

```
User sends message
       â”‚
       â–¼
Slack receives message
       â”‚
       â–¼
Socket Mode forwards to bot
       â”‚
       â–¼
slack_bot.py receives event
       â”‚
       â”œâ”€â–º Extract user message
       â”‚
       â–¼
Search Knowledge Base
       â”‚
       â”œâ”€â–º Embed query using sentence-transformers
       â”œâ”€â–º Search ChromaDB for similar content
       â””â”€â–º Return top 3 relevant chunks
       â”‚
       â–¼
Build Context Prompt
       â”‚
       â”œâ”€â–º Combine retrieved documents
       â”œâ”€â–º Add conversation history
       â””â”€â–º Format prompt for Llama
       â”‚
       â–¼
Generate Response with Llama
       â”‚
       â”œâ”€â–º Send to Ollama API
       â”œâ”€â–º Llama processes with context
       â””â”€â–º Return AI response
       â”‚
       â–¼
Format and Send to Slack
       â”‚
       â”œâ”€â–º Add source citations
       â”œâ”€â–º Format message
       â””â”€â–º Send via Slack API
```

## Component Details

### 1. slack_bot.py
**Purpose:** Main application entry point
**Functions:**
- Listen for Slack events (mentions, DMs)
- Handle slash commands
- Coordinate between AI and knowledge base
- Format responses

### 2. llama_ai.py
**Purpose:** AI response generation
**Functions:**
- Communicate with Ollama
- Manage conversation history
- Build prompts with context
- Handle model interactions

### 3. knowledge_base_manager.py
**Purpose:** Document storage and retrieval
**Functions:**
- Load documents (PDF, DOCX, TXT)
- Chunk text for embedding
- Store in ChromaDB
- Semantic search
- Return relevant context

### 4. ChromaDB
**Purpose:** Vector database
**Storage:**
- Document embeddings
- Metadata (source, type)
- Efficient similarity search

### 5. Ollama
**Purpose:** Run Llama models locally
**Features:**
- No external API calls
- Privacy-focused
- Free to use
- Multiple model options

## File Structure

```
slack-ai-bot/
â”‚
â”œâ”€â”€ Core Application Files
â”‚   â”œâ”€â”€ slack_bot.py              # Main bot application
â”‚   â”œâ”€â”€ llama_ai.py               # AI handler
â”‚   â”œâ”€â”€ knowledge_base_manager.py # Search engine
â”‚   â””â”€â”€ requirements.txt          # Dependencies
â”‚
â”œâ”€â”€ Configuration
â”‚   â”œâ”€â”€ .env                      # Your secrets (create this)
â”‚   â”œâ”€â”€ .env.example             # Template
â”‚   â””â”€â”€ .gitignore               # Git ignore rules
â”‚
â”œâ”€â”€ Setup Scripts
â”‚   â”œâ”€â”€ setup.sh                 # Linux/Mac setup
â”‚   â”œâ”€â”€ setup.bat                # Windows setup
â”‚   â””â”€â”€ test_setup.py            # Verify installation
â”‚
â”œâ”€â”€ Documentation
â”‚   â”œâ”€â”€ README.md                # Complete guide
â”‚   â”œâ”€â”€ QUICKSTART.md            # 5-minute setup
â”‚   â””â”€â”€ sample_faq.txt           # Example knowledge base
â”‚
â””â”€â”€ Data (created at runtime)
    â”œâ”€â”€ knowledge_base/          # Your documents
    â”‚   â”œâ”€â”€ chroma_db/          # Vector database
    â”‚   â”œâ”€â”€ document1.pdf
    â”‚   â””â”€â”€ faq.txt
    â””â”€â”€ venv/                    # Python virtual environment
```

## Technology Stack

### Backend
- **Python 3.8+**: Core language
- **Slack Bolt**: Slack integration framework
- **Socket Mode**: Real-time Slack connection

### AI Components
- **Ollama**: Run Llama models locally
- **Llama 3.2**: Language model (3B parameters)
- **Sentence Transformers**: Text embeddings

### Data Storage
- **ChromaDB**: Vector database
- **PyPDF2**: PDF processing
- **python-docx**: Word document processing

## Key Features Explained

### 1. Socket Mode
- No public URL needed
- Works behind firewalls
- Real-time bidirectional communication
- Easier development setup

### 2. Semantic Search
- Converts text to vector embeddings
- Finds similar content (not just keywords)
- Returns relevant context for AI
- Efficient with large knowledge bases

### 3. Conversation Memory
- Stores last 5 exchanges per user
- Provides context to AI
- Makes conversations natural
- Automatically managed

### 4. Context-Aware Responses
- Searches knowledge base first
- Provides sources to AI
- AI can cite specific documents
- Falls back to general knowledge

## Message Flow Example

```
User: "@BotName what's the refund policy?"
  â”‚
  â–¼
Knowledge Base Search:
  - "refund policy" â†’ embedding
  - ChromaDB finds: "30-day money-back guarantee..."
  â”‚
  â–¼
Build Prompt:
  "Here is relevant info: [Source: FAQ] 30-day money-back...
   Question: what's the refund policy?"
  â”‚
  â–¼
Llama Generates:
  "We offer a 30-day money-back guarantee. If you're not
   satisfied, contact support for a full refund within 30 days."
  â”‚
  â–¼
Format Response:
  "@User We offer a 30-day money-back guarantee...
   ğŸ“š Sources: FAQ"
  â”‚
  â–¼
Send to Slack âœ“
```

## Security Considerations

### Data Privacy
- All processing happens locally
- No data sent to external AI APIs
- Knowledge base stored on your machine
- Slack tokens kept in .env (not in code)

### Access Control
- Bot only responds to authorized workspace
- Conversation history per user
- Slack handles authentication
- Can restrict to specific channels

## Scaling Considerations

### Current Setup (Good for):
- Small to medium teams (< 100 users)
- 1,000-10,000 messages/day
- Knowledge base < 10,000 documents
- Single server deployment

### To Scale Up:
- Use PostgreSQL for conversation history
- Deploy ChromaDB separately
- Load balance multiple bot instances
- Use GPUs for faster Llama inference
- Consider cloud-hosted Ollama

## Performance Tips

1. **Model Selection:**
   - llama3.2:1b - Fastest, basic quality
   - llama3.2:3b - Balanced (recommended)
   - llama3.1:8b - Best quality, slower

2. **Knowledge Base:**
   - Keep documents focused and relevant
   - Remove outdated content
   - Use clear, concise language
   - Organize by topic

3. **Search Results:**
   - Adjust n_results (default: 3)
   - Balance speed vs context
   - Monitor ChromaDB performance

4. **Conversation History:**
   - Current: Last 5 exchanges
   - Adjust based on needs
   - Clear when changing topics

## Troubleshooting Guide

### Bot Not Responding
1. Check Ollama: `ollama list`
2. Check bot logs in terminal
3. Verify Slack tokens in .env
4. Test with: `python test_setup.py`

### Slow Responses
1. Try smaller model: `llama3.2:1b`
2. Reduce search results: `n_results=2`
3. Clear conversation history
4. Check system resources

### Inaccurate Answers
1. Add more knowledge base content
2. Update outdated documents
3. Increase search results: `n_results=5`
4. Try larger model: `llama3.1:8b`

### Import Errors
```bash
pip install -r requirements.txt --upgrade
```

### ChromaDB Issues
Delete and rebuild:
```bash
rm -rf knowledge_base/chroma_db
python slack_bot.py  # Rebuilds automatically
```
